{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Biclustering documents with the Spectral Co-clustering algorithm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOUTENbtdolcvtdN2odL86U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coldman22/Coldman22-biclustering/blob/main/Biclustering_documents_with_the_Spectral_Co_clustering_algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Biclustering documents with the Spectral Co-clustering algorithm"
      ],
      "metadata": {
        "id": "2_1CjzLs3zcs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FUC3ONiy3wqQ"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import operator\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "2SZVWjep35nx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import SpectralCoclustering\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.cluster import v_measure_score"
      ],
      "metadata": {
        "id": "7E2s-YAV37yn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def number_normalizer(tokens):\n",
        "    \"\"\"Map all numeric tokens to a placeholder.\n",
        "\n",
        "    For many applications, tokens that begin with a number are not directly\n",
        "    useful, but the fact that such a token exists can be relevant.  By applying\n",
        "    this form of dimensionality reduction, some methods may perform better.\n",
        "    \"\"\"\n",
        "    return (\"#NUMBER\" if token[0].isdigit() else token for token in tokens)"
      ],
      "metadata": {
        "id": "vgjTrTNh371p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NumberNormalizingVectorizer(TfidfVectorizer):\n",
        "    def build_tokenizer(self):\n",
        "        tokenize = super().build_tokenizer()\n",
        "        return lambda doc: list(number_normalizer(tokenize(doc)))"
      ],
      "metadata": {
        "id": "9Khqke2X374U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exclude 'comp.os.ms-windows.misc'\n",
        "categories = [\n",
        "    \"alt.atheism\",\n",
        "    \"comp.graphics\",\n",
        "    \"comp.sys.ibm.pc.hardware\",\n",
        "    \"comp.sys.mac.hardware\",\n",
        "    \"comp.windows.x\",\n",
        "    \"misc.forsale\",\n",
        "    \"rec.autos\",\n",
        "    \"rec.motorcycles\",\n",
        "    \"rec.sport.baseball\",\n",
        "    \"rec.sport.hockey\",\n",
        "    \"sci.crypt\",\n",
        "    \"sci.electronics\",\n",
        "    \"sci.med\",\n",
        "    \"sci.space\",\n",
        "    \"soc.religion.christian\",\n",
        "    \"talk.politics.guns\",\n",
        "    \"talk.politics.mideast\",\n",
        "    \"talk.politics.misc\",\n",
        "    \"talk.religion.misc\",\n",
        "]"
      ],
      "metadata": {
        "id": "y75IUISu377c"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newsgroups = fetch_20newsgroups(categories=categories)\n",
        "y_true = newsgroups.target\n",
        "\n",
        "vectorizer = NumberNormalizingVectorizer(stop_words=\"english\", min_df=5)\n",
        "cocluster = SpectralCoclustering(\n",
        "    n_clusters=len(categories), svd_method=\"arpack\", random_state=0\n",
        ")\n",
        "kmeans = MiniBatchKMeans(n_clusters=len(categories), batch_size=20000, random_state=0)"
      ],
      "metadata": {
        "id": "Mh36Z0Y_37-B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vectorizing...\")\n",
        "X = vectorizer.fit_transform(newsgroups.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmBkgzg44R8I",
        "outputId": "d10e2096-70b6-43b2-e612-daf90ba8f25c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorizing...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Coclustering...\")\n",
        "start_time = time()\n",
        "cocluster.fit(X)\n",
        "y_cocluster = cocluster.row_labels_\n",
        "print(\n",
        "    \"Done in {:.2f}s. V-measure: {:.4f}\".format(\n",
        "        time() - start_time, v_measure_score(y_cocluster, y_true)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlrvhkja4R_B",
        "outputId": "b1aa42f1-0d12-4375-bfd4-8d855eba4020"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coclustering...\n",
            "Done in 7.74s. V-measure: 0.4431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MiniBatchKMeans...\")\n",
        "start_time = time()\n",
        "y_kmeans = kmeans.fit_predict(X)\n",
        "print(\n",
        "    \"Done in {:.2f}s. V-measure: {:.4f}\".format(\n",
        "        time() - start_time, v_measure_score(y_kmeans, y_true)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn_DyivI4SB5",
        "outputId": "8d88e1ec-3a80-4641-f8ca-06bb4a6a6c40"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MiniBatchKMeans...\n",
            "Done in 7.75s. V-measure: 0.3177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = vectorizer.get_feature_names_out()\n",
        "document_names = list(newsgroups.target_names[i] for i in newsgroups.target)"
      ],
      "metadata": {
        "id": "uAXGrMDo4gOr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bicluster_ncut(i):\n",
        "    rows, cols = cocluster.get_indices(i)\n",
        "    if not (np.any(rows) and np.any(cols)):\n",
        "        import sys\n",
        "\n",
        "        return sys.float_info.max\n",
        "    row_complement = np.nonzero(np.logical_not(cocluster.rows_[i]))[0]\n",
        "    col_complement = np.nonzero(np.logical_not(cocluster.columns_[i]))[0]\n",
        "    # Note: the following is identical to X[rows[:, np.newaxis],\n",
        "    # cols].sum() but much faster in scipy <= 0.16\n",
        "    weight = X[rows][:, cols].sum()\n",
        "    cut = X[row_complement][:, cols].sum() + X[rows][:, col_complement].sum()\n",
        "    return cut / weight"
      ],
      "metadata": {
        "id": "BsMHaYoT4gTL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def most_common(d):\n",
        "    \"\"\"Items of a defaultdict(int) with the highest values.\n",
        "\n",
        "    Like Counter.most_common in Python >=2.7.\n",
        "    \"\"\"\n",
        "    return sorted(d.items(), key=operator.itemgetter(1), reverse=True)\n",
        "\n",
        "\n",
        "bicluster_ncuts = list(bicluster_ncut(i) for i in range(len(newsgroups.target_names)))\n",
        "best_idx = np.argsort(bicluster_ncuts)[:5]\n",
        "\n",
        "print()\n",
        "print(\"Best biclusters:\")\n",
        "print(\"----------------\")\n",
        "for idx, cluster in enumerate(best_idx):\n",
        "    n_rows, n_cols = cocluster.get_shape(cluster)\n",
        "    cluster_docs, cluster_words = cocluster.get_indices(cluster)\n",
        "    if not len(cluster_docs) or not len(cluster_words):\n",
        "        continue\n",
        "\n",
        "    # categories\n",
        "    counter = defaultdict(int)\n",
        "    for i in cluster_docs:\n",
        "        counter[document_names[i]] += 1\n",
        "    cat_string = \", \".join(\n",
        "        \"{:.0f}% {}\".format(float(c) / n_rows * 100, name)\n",
        "        for name, c in most_common(counter)[:3]\n",
        "    )\n",
        "\n",
        "    # words\n",
        "    out_of_cluster_docs = cocluster.row_labels_ != cluster\n",
        "    out_of_cluster_docs = np.where(out_of_cluster_docs)[0]\n",
        "    word_col = X[:, cluster_words]\n",
        "    word_scores = np.array(\n",
        "        word_col[cluster_docs, :].sum(axis=0)\n",
        "        - word_col[out_of_cluster_docs, :].sum(axis=0)\n",
        "    )\n",
        "    word_scores = word_scores.ravel()\n",
        "    important_words = list(\n",
        "        feature_names[cluster_words[i]] for i in word_scores.argsort()[:-11:-1]\n",
        "    )\n",
        "\n",
        "    print(\"bicluster {} : {} documents, {} words\".format(idx, n_rows, n_cols))\n",
        "    print(\"categories   : {}\".format(cat_string))\n",
        "    print(\"words        : {}\\n\".format(\", \".join(important_words)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vGPJKT84tRp",
        "outputId": "54719cd7-bb56-40e2-d609-9020556d7050"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best biclusters:\n",
            "----------------\n",
            "bicluster 0 : 1961 documents, 4388 words\n",
            "categories   : 23% talk.politics.guns, 18% talk.politics.misc, 17% sci.med\n",
            "words        : gun, geb, guns, banks, gordon, clinton, pitt, cdt, surrender, veal\n",
            "\n",
            "bicluster 1 : 1269 documents, 3558 words\n",
            "categories   : 27% soc.religion.christian, 25% talk.politics.mideast, 24% alt.atheism\n",
            "words        : god, jesus, christians, sin, objective, kent, belief, christ, faith, moral\n",
            "\n",
            "bicluster 2 : 2201 documents, 2747 words\n",
            "categories   : 18% comp.sys.mac.hardware, 17% comp.sys.ibm.pc.hardware, 16% comp.graphics\n",
            "words        : voltage, board, dsp, packages, receiver, stereo, shipping, package, compression, image\n",
            "\n",
            "bicluster 3 : 1773 documents, 2620 words\n",
            "categories   : 27% rec.motorcycles, 23% rec.autos, 13% misc.forsale\n",
            "words        : bike, car, dod, engine, motorcycle, ride, honda, bikes, helmet, bmw\n",
            "\n",
            "bicluster 4 : 201 documents, 1175 words\n",
            "categories   : 81% talk.politics.mideast, 10% alt.atheism, 7% soc.religion.christian\n",
            "words        : turkish, armenia, armenian, armenians, turks, petch, sera, zuma, argic, gvg47\n",
            "\n"
          ]
        }
      ]
    }
  ]
}